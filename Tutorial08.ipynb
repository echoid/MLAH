{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um2pyaJP3b_N"
      },
      "source": [
        "# Machine Learning Applications for Health (COMP90089_2022_SM2)\n",
        "# Tutorial 8: Deep Learning with MIMIC-IV clinical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB0mWgUM3iKe"
      },
      "source": [
        "> ### Goal: Predict the mortality risk for Sepsis Cohort\n",
        "\n",
        "####Deep Learning Neural Networks\n",
        "\n",
        "\n",
        "* **Data** set: query the cohort in MIMIC-IV \n",
        "* Create the machine learning model with **Keras Library**\n",
        "* **Compile** the model\n",
        "* **Fit** the model using the training data set\n",
        "* **Evaluate** the performance of the model\n",
        "* **Predict** testing data set (unseen data)\n",
        "\n",
        "\n",
        "This Tutorial was based on this [source](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEHRht-36bj2"
      },
      "source": [
        "### Set up the main **libraries**: keras, numpy, pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_yIFY9u5zK-"
      },
      "outputs": [],
      "source": [
        "# !pip install -q keras #Uncomment and run this cell to install Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "huZghbUb63Y6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Access data using Google BigQuery.\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None) ##This is only to show all columns when printing a DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weFGJb7f1K-D"
      },
      "source": [
        "* Authenticate in the BigQuery platform. Define the function to query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3gbev8Mj06HS"
      },
      "outputs": [],
      "source": [
        "# authenticate\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oMKOBlsz0777"
      },
      "outputs": [],
      "source": [
        "# Set up environment variables\n",
        "project_id = 'CHANGE-ME' ##Change only this variable with your project ID in BigQuery Platform.\n",
        "if project_id == 'CHANGE-ME': #No Need to change this one!\n",
        "  raise ValueError('You must change project_id to your GCP project.')\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
        "\n",
        "# Read data from BigQuery into pandas dataframes.\n",
        "def run_query(query, project_id=project_id):\n",
        "  return pd.io.gbq.read_gbq(\n",
        "      query,\n",
        "      project_id=project_id,\n",
        "      dialect='standard')\n",
        "\n",
        "# set the dataset\n",
        "dataset = 'mimiciv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrpjACnY79AK"
      },
      "source": [
        "## **Data set**\n",
        "We'll use a cohort derived from MIMIC-IV.\n",
        "\n",
        "* The query bellow is searching for the data in the **BigQuery Platform**.\n",
        "* We are retrieving patients with **Sepsis**: A life-threatening complication caused by the body's response to an infection. When your immune system goes into **overdrive in response to an infection**, sepsis may develop as a result\n",
        "* Further, we will join the Date of Death information, the age and gender from patients table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wfxeUfd09wU"
      },
      "outputs": [],
      "source": [
        "##We are retrieving patients using sepsis3 Table and joining it to patients Table.\n",
        "\n",
        "df = run_query(\"\"\"\n",
        "SELECT sep.subject_id,sep.sofa_score,sep.respiration,sep.coagulation,sep.liver,sep.cardiovascular,sep.cns,sep.renal,pt.dod,pt.anchor_age,pt.gender\n",
        "FROM `physionet-data.mimiciv_derived.sepsis3` as sep\n",
        "INNER JOIN `physionet-data.mimiciv_hosp.patients` as pt\n",
        "ON sep.subject_id = pt.subject_id\n",
        "ORDER BY subject_id\n",
        "\"\"\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrJwgCxE3k3P"
      },
      "source": [
        "* Analyse the data as we did in the previous Tutorial: missing values, transform categorical into numerical, check dtype of each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ijM6sI13V02"
      },
      "outputs": [],
      "source": [
        "dataset = df.copy()\n",
        "\n",
        "#Replace Date of Death times with binary (0 or 1)\n",
        "dataset.loc[dataset['dod'].notna(),'dod'] = int(1)\n",
        "dataset.loc[dataset['dod'].isnull(),'dod'] = int(0)\n",
        "dataset['dod'] = dataset['dod'].astype(int)\n",
        "\n",
        "#Transform Gender column from Categorical Data to Binary:\n",
        "gender_categorical = pd.get_dummies(dataset['gender'])\n",
        "\n",
        "#Concatenate both Data frames:\n",
        "final_sepsis = pd.concat([dataset,gender_categorical], axis = 1)\n",
        "\n",
        "#Final Data set to work with:\n",
        "final_sepsis = final_sepsis.drop(['subject_id','gender'], axis = 1)\n",
        "print(final_sepsis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeWCMd3N4Mn-"
      },
      "outputs": [],
      "source": [
        "#Check the final dtype of each column. Are they properly defined now? \n",
        "print(final_sepsis.info(),\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c4JYspQ2grp"
      },
      "source": [
        "* Split the data set into Training and Testing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpFsbmXR7fuY"
      },
      "outputs": [],
      "source": [
        "# split into input (X) and output (y) variables\n",
        "target = 'dod'\n",
        "X = final_sepsis.drop(labels = target, axis = 1) #Remove the target column from the dataset and create the independent(features) variables set\n",
        "y = final_sepsis[target]\n",
        "\n",
        "#Adjust the size of the testing set: we'll use 10% of the entire data. \n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)\n",
        "\n",
        "#Check the number of columns (features):\n",
        "print(X_train.columns)\n",
        "print(len(X_train.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGJlpnK48Snn"
      },
      "source": [
        "##Define Keras Model\n",
        "* Models in Keras are defined as a sequence of layers.\n",
        "\n",
        "* Create a Sequential model and add [layers](https://keras.io/api/layers/core_layers/) one at a time until satisfied with the network architecture. Read more [here](https://keras.io/api/models/sequential/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIsYV2ln8v7c"
      },
      "source": [
        "Note:  **the shape of the input to the model** is defined as an argument on the first hidden layer. \n",
        "\n",
        "This means that the line of code that adds the first Dense layer is doing two things:\n",
        "\n",
        "* Defining the input (training columns size) with **input_shape** argument as a vector.\n",
        "* Defining the first hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PyyBaLe78SyS"
      },
      "outputs": [],
      "source": [
        "# Define the keras model. In this example we are using fully-connected network structure (Dense class) with four layers (adding 4 times)\n",
        "model = Sequential()\n",
        "\n",
        "#The first hidden layer has 120 nodes and uses the relu activation function.\n",
        "model.add(Dense(120, input_shape=(10,), activation='relu')) #'relu': rectified linear activation function\n",
        "\n",
        "#The second hidden layer has 30 nodes and uses the relu activation function.\n",
        "model.add(Dense(30, activation='relu')) #'relu': rectified linear activation function\n",
        "\n",
        "#The output layer has 1 node and uses the sigmoid activation function.\n",
        "model.add(Dense(1, activation='sigmoid')) # Using a sigmoid on the output layer ensures your network output is between 0 and 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F36kleTC9O7m"
      },
      "source": [
        "\n",
        "###Compile Keras Model\n",
        "* Now that the model is defined, you can compile it.\n",
        "Remember that training a network means **finding the best set of weights** to map inputs to outputs in your dataset.\n",
        "\n",
        "* Specify the [**loss function**](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/) to use to evaluate a set of weights, the **optimizer** used to search through different weights for the network, and the [**metrics**](https://keras.io/api/metrics/) to evaluate the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i0j2rbkI9GW3"
      },
      "outputs": [],
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#cross entropy as the loss argument. This loss is for binary classification problems.\n",
        "#stochastic gradient descent algorithm “adam“"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T0ZekcH9xtr"
      },
      "source": [
        "###Fit Keras Model\n",
        "* You have defined your model and compiled it to get ready for efficient computation.\n",
        "\n",
        "* Now it is time to execute the model on some data: train or fit your model on your loaded data by calling the fit() function on the model.\n",
        "\n",
        "Training occurs over epochs, and each epoch is split into batches. Read more [here](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/).\n",
        "\n",
        "* **Epoch:** One pass through all of the rows in the training dataset\n",
        "* **Batch:** One or more samples considered by the model within an epoch before weights are updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dpVvKQL9yT7"
      },
      "outputs": [],
      "source": [
        "# fit the keras model on the dataset\n",
        "classifier = model.fit(X_train, y_train, epochs=200, batch_size=100, verbose=1) #set verbose = 1 to see the fitting process on screen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDU6ZlsOThUv"
      },
      "source": [
        "### Let's visualise the behavior of the model in terms of loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYarqIRyOLtU"
      },
      "outputs": [],
      "source": [
        "# Get the history data for the classifier:\n",
        "print(classifier.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nMwajUNPNz0"
      },
      "outputs": [],
      "source": [
        "# Plot Accuracy over the epochs\n",
        "plt.plot(classifier.history['accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.title('model accuracy')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss over the epochs\n",
        "plt.plot(classifier.history['loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title('model loss')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbkGtP1LCOkS"
      },
      "source": [
        "###Evaluate Keras Model\n",
        "\n",
        "* Ideally, you would like the loss to go to zero and the accuracy to go to 1.0 (e.g., 100%). This is not possible for any but the most trivial machine learning problems. \n",
        "* Instead, you will always have some error in your model. The goal is to **choose a model configuration and training configuration that achieve the lowest loss and highest accuracy possible** for a given dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VewsKS-UB--C"
      },
      "outputs": [],
      "source": [
        "# evaluate the keras model\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "print(loss,accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhrfPbyDEFNn"
      },
      "source": [
        "### Make Predictions and Assess the Performance on Testing set (Blind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "218Hkc3uEFbA"
      },
      "outputs": [],
      "source": [
        "# #Predict the testing set\n",
        "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "#Accuracy classification score\n",
        "acc = float(round(metrics.accuracy_score(y_test, predictions),3))\n",
        "\n",
        "#Compute the balanced accuracy.\n",
        "bacc = float(round(metrics.balanced_accuracy_score(y_test, predictions),3))\n",
        "\n",
        "#Compute the Matthews correlation coefficient (MCC)\n",
        "mcc = float(round(metrics.matthews_corrcoef(y_test, predictions),3))\n",
        "\n",
        "#Compute the F1 score, also known as balanced F-score or F-measure.\n",
        "f1 = float(round(metrics.f1_score(y_test, predictions),3))\n",
        "\n",
        "#Show results as a DataFrame:\n",
        "results = {'Accuracy' : [acc], 'Balanced Accuracy' : [bacc], 'MCC' : [mcc], 'F1-Score' : [f1]}\n",
        "df_results = pd.DataFrame.from_dict(data = results, orient='columns')\n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VSrIxfcwOvz"
      },
      "source": [
        "* Discussion: How can you compare this result with the previous (unsupervised with the same Sepsis data)?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "47e86d731e077963188d400b641a1f5cee6401b89b8a1175acb1a082248e2517"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
